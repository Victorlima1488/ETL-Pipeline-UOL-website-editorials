{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com redações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/qualificacoes-para-o-mercado-de-trabalho.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-apropriacao-cultural-e-o-conhecimento-historico.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/no-mes-de-fevereiro-muitos-paises.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-atualidades.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/representacao-indigena-no-meio-social.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-afronta-carnavalesca.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-uma-festa-de-cultura.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-ou-cultura.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/monopolio-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-tao-necessaria-quanto-natural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-significa-uma-pessoa.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/dar-voz-para-quem-nao-a-possui.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-sinonimo-de-composicao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/multiculturalismo-carnavalesco.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-ou-intercambio.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-apropriacao-cultural-continua.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/muito-alem-da-fantasia.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/as-fantasias-no-carnaval.htm\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-so-no-carnaval.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/entender-o-outro.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-o-racismo-velado.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/uniao-entre-o-orgao-publico-e-a-opiniao-publica.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-democracia-estende-se-ao-stf.html\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório e nomes dos arquivos\n",
    "output_dir = \"textos_uol\"\n",
    "output_file = os.path.join(output_dir, \"dados_redacoes.csv\")\n",
    "processed_links_file = os.path.join(output_dir, \"processados.txt\")\n",
    "title_file = os.path.join(output_dir, \"titulos.csv\")\n",
    "id_file = os.path.join(output_dir, \"ultimo_id.txt\")\n",
    "\n",
    "# Certifica-se de que o diretório existe, e se não, cria-o\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Carrega o último ID salvo (chave incremental) ou define como 0\n",
    "if os.path.exists(id_file):\n",
    "    with open(id_file, \"r\") as f:\n",
    "        last_id = int(f.read().strip())\n",
    "else:\n",
    "    last_id = 0\n",
    "\n",
    "# Função para gerar o próximo ID incremental\n",
    "def generate_id():\n",
    "    global last_id\n",
    "    last_id += 1\n",
    "    return f\"{last_id:06d}\"\n",
    "\n",
    "# Carrega os links já processados para evitar duplicação\n",
    "if os.path.exists(processed_links_file):\n",
    "    with open(processed_links_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_links = set(line.strip() for line in f)\n",
    "else:\n",
    "    processed_links = set()\n",
    "\n",
    "# Verifica se o arquivo principal já existe para definir o modo de abertura e o cabeçalho\n",
    "file_mode = \"a\" if os.path.exists(output_file) else \"w\"\n",
    "\n",
    "# Abre o arquivo CSV principal para escrita e define o cabeçalho se necessário\n",
    "with open(output_file, mode=file_mode, newline=\"\", encoding=\"utf-8\") as main_file:\n",
    "\n",
    "    writer_main = csv.writer(main_file)\n",
    "    \n",
    "    # Escreve o cabeçalho no CSV principal\n",
    "    if file_mode == \"w\":\n",
    "        writer_main.writerow([\"ID\", \"Título\", \"Subtítulo\", \"Texto da Redação\", \"Competências\", \"Notas das Competências\", \"Comentários das Competências\", \"Nota Final\"])\n",
    "\n",
    "    # Abre o arquivo de títulos em modo \"w\" para garantir o cabeçalho limpo e correto\n",
    "    with open(title_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as title_file_obj:\n",
    "        writer_title = csv.writer(title_file_obj)\n",
    "        # Escreve o cabeçalho para o arquivo de títulos\n",
    "        writer_title.writerow([\"ID\", \"Título\"])\n",
    "\n",
    "        # Processa cada URL na lista\n",
    "        for url in urls:\n",
    "            if url in processed_links:\n",
    "                print(f\"URL já processada, ignorando: {url}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Gera um novo ID para a linha atual\n",
    "                record_id = generate_id()\n",
    "\n",
    "                # Realiza a requisição GET para obter o conteúdo da página\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()  # Verifica se houve algum erro na requisição\n",
    "\n",
    "                # Cria um objeto BeautifulSoup para analisar o HTML da página\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Extrai o título da redação\n",
    "                title_tag = soup.find('i', class_='custom-title')\n",
    "                title = title_tag.get_text(strip=True) if title_tag else \"Título não encontrado\"\n",
    "\n",
    "                # Extrai o subtítulo da redação (h2 dentro de container-composition dentro de wording-correction)\n",
    "                section_wording_correction = soup.find('section', class_='wording-correction')\n",
    "                container_composition = section_wording_correction.find('div', class_='container-composition') if section_wording_correction else None\n",
    "                subtitle_tag = container_composition.find('h2') if container_composition else None\n",
    "                subtitle = subtitle_tag.get_text(strip=True) if subtitle_tag else \"Subtítulo não encontrado\"\n",
    "\n",
    "                # Grava o título principal no arquivo de títulos, com o ID gerado\n",
    "                writer_title.writerow([record_id, title])\n",
    "\n",
    "                # Extrai o texto da redação dentro da tag 'text-composition'\n",
    "                essay_section = soup.find('div', class_='text-composition')\n",
    "                essay_text = \" \".join([p.get_text(strip=True) for p in essay_section.find_all('p')]) if essay_section else \"Redação não encontrada\"\n",
    "\n",
    "                # Extrai as competências e notas, ignorando a \"Nota Final\"\n",
    "                competence_scores_section = soup.find('section', class_='results-table')\n",
    "                competence_scores_list = competence_scores_section.find_all('div', class_='rt-line-option') if competence_scores_section else []\n",
    "\n",
    "                # Listas para armazenar competências, notas, e comentários (excluindo a Nota Final)\n",
    "                competences = []\n",
    "                competence_scores = []\n",
    "                final_score = \"Nota final não encontrada\"\n",
    "\n",
    "                for score in competence_scores_list:\n",
    "                    topic = score.find('span', class_='topic').get_text(strip=True)\n",
    "                    points = score.find('span', class_='points').get_text(strip=True)\n",
    "                    \n",
    "                    if \"Nota final\" in topic:\n",
    "                        final_score = points  # Armazena a nota final separadamente\n",
    "                    else:\n",
    "                        competences.append(topic)\n",
    "                        competence_scores.append(points)\n",
    "\n",
    "                # Extrai os comentários das competências\n",
    "                competence_comments_section = soup.find('h3', string=\"Competências\")\n",
    "                competence_comments_list = competence_comments_section.find_next('ul').find_all('li') if competence_comments_section else []\n",
    "                competence_comments = [comment.get_text(strip=True) for comment in competence_comments_list]\n",
    "                concatenated_comments = \"; \".join(competence_comments)\n",
    "\n",
    "                # Concatena as competências e as notas (sem a Nota Final) usando \";\" como separador\n",
    "                concatenated_competences = \"; \".join(competences)\n",
    "                concatenated_scores = \"; \".join(competence_scores)\n",
    "\n",
    "                # Escreve uma linha no CSV principal para cada URL processada\n",
    "                writer_main.writerow([record_id, title, subtitle, essay_text, concatenated_competences, concatenated_scores, concatenated_comments, final_score])\n",
    "\n",
    "                # Marca a URL como processada e salva no arquivo de links processados\n",
    "                with open(processed_links_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(url + \"\\n\")\n",
    "                \n",
    "                print(f\"Processado com sucesso: {url}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Erro ao acessar a página {url}: {e}\")\n",
    "\n",
    "# Salva o último ID usado\n",
    "with open(id_file, \"w\") as f:\n",
    "    f.write(str(last_id))\n",
    "\n",
    "print(f\"Arquivos CSV salvos em: {output_file} e {title_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com propostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/qualificacao-e-o-futuro-do-emprego.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/supremo-tribunal-federal-e-opiniao-publica.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/supremo-tribunal-federal-e-opiniao-publica.html\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar os textos das propostas extraídos\n",
    "textos_propostas = []\n",
    "\n",
    "# Loop para processar cada URL\n",
    "for url in urls:\n",
    "    try:\n",
    "        # Faz a requisição para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Cria o objeto BeautifulSoup para analisar o HTML da página\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Localiza a cadeia de divs: article-wording -> calc-height -> image-content-pad -> text\n",
    "        article_wording = soup.find('div', class_='article-wording')\n",
    "        if article_wording:\n",
    "            calc_height = article_wording.find('div', class_='calc-height')\n",
    "            if calc_height:\n",
    "                image_content_pad = calc_height.find('div', class_='image-content-pad')\n",
    "                if image_content_pad:\n",
    "                    text_div = image_content_pad.find('div', class_='text')\n",
    "                    \n",
    "                    # Extrai o conteúdo das tags <p> dentro de \"text\"\n",
    "                    if text_div:\n",
    "                        paragraphs = text_div.find_all('p', recursive=False)\n",
    "                        text_proposal = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "                    else:\n",
    "                        text_proposal = \"Seção de texto não encontrada na div 'text'.\"\n",
    "                else:\n",
    "                    text_proposal = \"Div 'image-content-pad' não encontrada.\"\n",
    "            else:\n",
    "                text_proposal = \"Div 'calc-height' não encontrada.\"\n",
    "        else:\n",
    "            text_proposal = \"Div 'article-wording' não encontrada.\"\n",
    "\n",
    "        # Adiciona o texto extraído à lista de resultados\n",
    "        textos_propostas.append({\"url\": url, \"texto_proposta\": text_proposal})\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro ao acessar a URL {url}: {e}\")\n",
    "        textos_propostas.append({\"url\": url, \"texto_proposta\": \"Erro ao acessar a página\"})\n",
    "\n",
    "# Exibe os textos das propostas extraídos\n",
    "for proposta in textos_propostas:\n",
    "    print(f\"\\nURL: {proposta['url']}\")\n",
    "    print(f\"Texto de Proposta:\\n{proposta['texto_proposta']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando extração de textos das propostas...\n",
      "\n",
      "Processando URL 1/23: https://educacao.uol.com.br/bancoderedacoes/propostas/qualificacao-e-o-futuro-do-emprego.html\n",
      "Texto extraído com sucesso da URL 1\n",
      "\n",
      "Processando URL 2/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 2\n",
      "\n",
      "Processando URL 3/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 3\n",
      "\n",
      "Processando URL 4/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 4\n",
      "\n",
      "Processando URL 5/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 5\n",
      "\n",
      "Processando URL 6/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 6\n",
      "\n",
      "Processando URL 7/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 7\n",
      "\n",
      "Processando URL 8/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 8\n",
      "\n",
      "Processando URL 9/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 9\n",
      "\n",
      "Processando URL 10/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 10\n",
      "\n",
      "Processando URL 11/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 11\n",
      "\n",
      "Processando URL 12/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 12\n",
      "\n",
      "Processando URL 13/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 13\n",
      "\n",
      "Processando URL 14/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 14\n",
      "\n",
      "Processando URL 15/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 15\n",
      "\n",
      "Processando URL 16/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 16\n",
      "\n",
      "Processando URL 17/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 17\n",
      "\n",
      "Processando URL 18/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 18\n",
      "\n",
      "Processando URL 19/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 19\n",
      "\n",
      "Processando URL 20/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 20\n",
      "\n",
      "Processando URL 21/23: https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\n",
      "Texto extraído com sucesso da URL 21\n",
      "\n",
      "Processando URL 22/23: https://educacao.uol.com.br/bancoderedacoes/propostas/supremo-tribunal-federal-e-opiniao-publica.html\n",
      "Texto extraído com sucesso da URL 22\n",
      "\n",
      "Processando URL 23/23: https://educacao.uol.com.br/bancoderedacoes/propostas/supremo-tribunal-federal-e-opiniao-publica.html\n",
      "Texto extraído com sucesso da URL 23\n",
      "\n",
      "Extração de propostas concluída.\n",
      "Lendo arquivo CSV existente: textos_uol\\titulos.csv\n",
      "Leitura concluída.\n",
      "Adicionando coluna 'Textos Base' ao CSV.\n",
      "Atualizando o CSV com os textos extraídos...\n",
      "\n",
      "Arquivo 'textos_uol\\titulos.csv' atualizado com os textos das propostas na coluna 'Textos Base'.\n"
     ]
    }
   ],
   "source": [
    "# Diretório e nome do arquivo CSV\n",
    "output_dir = \"textos_uol\"\n",
    "title_file = os.path.join(output_dir, \"titulos.csv\")\n",
    "\n",
    "# Lista para armazenar os textos das propostas extraídos\n",
    "textos_propostas = []\n",
    "\n",
    "print(\"Iniciando extração de textos das propostas...\")\n",
    "\n",
    "# Loop para processar cada URL e extrair o texto da proposta\n",
    "for index, url in enumerate(urls):\n",
    "    print(f\"\\nProcessando URL {index + 1}/{len(urls)}: {url}\")\n",
    "    try:\n",
    "        # Faz a requisição para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Cria o objeto BeautifulSoup para analisar o HTML da página\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Localiza a cadeia de divs: article-wording -> calc-height -> image-content-pad -> text\n",
    "        article_wording = soup.find('div', class_='article-wording')\n",
    "        if article_wording:\n",
    "            calc_height = article_wording.find('div', class_='calc-height')\n",
    "            if calc_height:\n",
    "                image_content_pad = calc_height.find('div', class_='image-content-pad')\n",
    "                if image_content_pad:\n",
    "                    text_div = image_content_pad.find('div', class_='text')\n",
    "                    \n",
    "                    # Extrai o conteúdo das tags <p> dentro de \"text\"\n",
    "                    if text_div:\n",
    "                        paragraphs = text_div.find_all('p', recursive=False)\n",
    "                        text_proposal = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "                        print(f\"Texto extraído com sucesso da URL {index + 1}\")\n",
    "                    else:\n",
    "                        text_proposal = \"Seção de texto não encontrada na div 'text'.\"\n",
    "                        print(f\"Alerta: {text_proposal}\")\n",
    "                else:\n",
    "                    text_proposal = \"Div 'image-content-pad' não encontrada.\"\n",
    "                    print(f\"Alerta: {text_proposal}\")\n",
    "            else:\n",
    "                text_proposal = \"Div 'calc-height' não encontrada.\"\n",
    "                print(f\"Alerta: {text_proposal}\")\n",
    "        else:\n",
    "            text_proposal = \"Div 'article-wording' não encontrada.\"\n",
    "            print(f\"Alerta: {text_proposal}\")\n",
    "\n",
    "        # Adiciona o texto extraído à lista de resultados\n",
    "        textos_propostas.append(text_proposal)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_message = f\"Erro ao acessar a URL {url}: {e}\"\n",
    "        print(error_message)\n",
    "        textos_propostas.append(\"Erro ao acessar a página\")\n",
    "\n",
    "print(\"\\nExtração de propostas concluída.\")\n",
    "\n",
    "# Verifica se o arquivo CSV existe e lê os dados\n",
    "if os.path.exists(title_file):\n",
    "    print(f\"Lendo arquivo CSV existente: {title_file}\")\n",
    "    with open(title_file, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        fieldnames = reader.fieldnames\n",
    "        rows = list(reader)\n",
    "    print(\"Leitura concluída.\")\n",
    "\n",
    "    # Adiciona a coluna \"Textos Base\" se não estiver presente\n",
    "    if \"Textos Base\" not in fieldnames:\n",
    "        print(\"Adicionando coluna 'Textos Base' ao CSV.\")\n",
    "        fieldnames.append(\"Textos Base\")\n",
    "        for row in rows:\n",
    "            row[\"Textos Base\"] = \"\"  # Inicializa a coluna para cada linha existente\n",
    "else:\n",
    "    print(f\"Erro: O arquivo {title_file} não existe.\")\n",
    "    exit()\n",
    "\n",
    "# Adiciona os textos extraídos na coluna \"Textos Base\" na ordem dos URLs\n",
    "print(\"Atualizando o CSV com os textos extraídos...\")\n",
    "for i, row in enumerate(rows):\n",
    "    if i < len(textos_propostas):\n",
    "        row[\"Textos Base\"] = textos_propostas[i]\n",
    "\n",
    "# Escreve as mudanças de volta no arquivo CSV\n",
    "with open(title_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\nArquivo '{title_file}' atualizado com os textos das propostas na coluna 'Textos Base'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
