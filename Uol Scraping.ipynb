{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/qualificacoes-para-o-mercado-de-trabalho.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-apropriacao-cultural-e-o-conhecimento-historico.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/no-mes-de-fevereiro-muitos-paises.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-atualidades.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/representacao-indigena-no-meio-social.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-afronta-carnavalesca.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-uma-festa-de-cultura.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-ou-cultura.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/monopolio-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-tao-necessaria-quanto-natural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-significa-uma-pessoa.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/dar-voz-para-quem-nao-a-possui.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/carnaval-sinonimo-de-composicao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/multiculturalismo-carnavalesco.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-ou-intercambio.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-apropriacao-cultural-continua.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/muito-alem-da-fantasia.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/as-fantasias-no-carnaval.htm\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-so-no-carnaval.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/entender-o-outro.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/apropriacao-cultural-e-o-racismo-velado.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/uniao-entre-o-orgao-publico-e-a-opiniao-publica.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/redacoes/a-democracia-estende-se-ao-stf.html\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório e nomes dos arquivos\n",
    "output_dir = \"textos_uol\"\n",
    "output_file = os.path.join(output_dir, \"dados_redacoes.csv\")\n",
    "processed_links_file = os.path.join(output_dir, \"processados.txt\")\n",
    "title_file = os.path.join(output_dir, \"titulos.csv\")\n",
    "id_file = os.path.join(output_dir, \"ultimo_id.txt\")\n",
    "title_id_file = os.path.join(output_dir, \"ultimo_id_titulo.txt\")\n",
    "\n",
    "# Certifica-se de que o diretório existe, e se não, cria-o\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Carrega o último ID salvo para redações ou define como 0\n",
    "if os.path.exists(id_file):\n",
    "    with open(id_file, \"r\") as f:\n",
    "        last_id = int(f.read().strip())\n",
    "else:\n",
    "    last_id = 0\n",
    "\n",
    "# Carrega o último ID salvo para títulos ou define como 0\n",
    "if os.path.exists(title_id_file):\n",
    "    with open(title_id_file, \"r\") as f:\n",
    "        last_title_id = int(f.read().strip())\n",
    "else:\n",
    "    last_title_id = 0\n",
    "\n",
    "# Função para gerar o próximo ID incremental para redações\n",
    "def generate_id():\n",
    "    global last_id\n",
    "    last_id += 1\n",
    "    return f\"{last_id:06d}\"\n",
    "\n",
    "# Função para gerar o próximo ID incremental para títulos\n",
    "def generate_title_id():\n",
    "    global last_title_id\n",
    "    last_title_id += 1\n",
    "    return f\"{last_title_id:04d}\"\n",
    "\n",
    "# Carrega os links já processados para evitar duplicação\n",
    "if os.path.exists(processed_links_file):\n",
    "    with open(processed_links_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_links = set(line.strip() for line in f)\n",
    "else:\n",
    "    processed_links = set()\n",
    "\n",
    "# Carrega os títulos já inseridos para evitar duplicação\n",
    "existing_titles = {}\n",
    "if os.path.exists(title_file):\n",
    "    with open(title_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Ignora o cabeçalho\n",
    "        for row in reader:\n",
    "            title_id, title_text = row\n",
    "            existing_titles[title_text.strip()] = title_id.strip()\n",
    "\n",
    "# Configura o ChromeDriver no modo headless\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Inicializa o navegador Chrome com as opções configuradas\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Abre o arquivo CSV principal para escrita e define o cabeçalho se necessário\n",
    "file_mode = \"a\" if os.path.exists(output_file) else \"w\"\n",
    "with open(output_file, mode=file_mode, newline=\"\", encoding=\"utf-8\") as main_file:\n",
    "    writer_main = csv.writer(main_file)\n",
    "    \n",
    "    # Escreve o cabeçalho no CSV principal\n",
    "    if file_mode == \"w\":\n",
    "        writer_main.writerow([\"ID\", \"id_titulo\", \"Título\", \"Subtítulo\", \"Texto da Redação\", \"Competências\", \"Notas das Competências\", \"Comentários das Competências\", \"Nota Final\"])\n",
    "\n",
    "    # Abre o arquivo de títulos em modo \"a\" para adicionar títulos sem repetição\n",
    "    with open(title_file, mode=\"a\", newline=\"\", encoding=\"utf-8\") as title_file_obj:\n",
    "        writer_title = csv.writer(title_file_obj)\n",
    "        if not existing_titles:\n",
    "            writer_title.writerow([\"ID\", \"Título\"])  # Cabeçalho para o arquivo de títulos\n",
    "\n",
    "        # Processa cada URL na lista\n",
    "        for url in urls:\n",
    "            if url in processed_links:\n",
    "                print(f\"[INFO] URL já processada, ignorando: {url}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n[INFO] Processando URL: {url}\")\n",
    "            time.sleep(5)  # Pausa de 5 segundos antes de cada processamento\n",
    "            try:\n",
    "                # Gera um novo ID para a linha atual\n",
    "                record_id = generate_id()\n",
    "                print(f\"[INFO] ID gerado para o registro: {record_id}\")\n",
    "\n",
    "                # Abre a URL no navegador headless\n",
    "                driver.get(url)\n",
    "                print(f\"[SUCCESS] Conexão bem-sucedida com {url}\")\n",
    "\n",
    "                # Extrai o título da redação\n",
    "                try:\n",
    "                    title_tag = driver.find_element(By.CSS_SELECTOR, \"i.custom-title\")\n",
    "                    title = title_tag.text.strip() if title_tag else \"Título não encontrado\"\n",
    "                except:\n",
    "                    title = \"Título não encontrado\"\n",
    "                print(f\"[INFO] Título extraído: {title}\")\n",
    "\n",
    "                # Verifica se o título já está na lista de títulos inseridos\n",
    "                if title in existing_titles:\n",
    "                    title_id = existing_titles[title]  # Usa o ID existente para o título\n",
    "                else:\n",
    "                    title_id = generate_title_id()  # Gera um novo ID para o título\n",
    "                    writer_title.writerow([title_id, title])\n",
    "                    existing_titles[title] = title_id  # Adiciona o título e ID ao dicionário\n",
    "                    print(f\"[INFO] Título adicionado ao arquivo de títulos: {title}\")\n",
    "\n",
    "                # Extrai o subtítulo da redação\n",
    "                try:\n",
    "                    subtitle_tag = driver.find_element(By.CSS_SELECTOR, \"section.wording-correction h2\")\n",
    "                    subtitle = subtitle_tag.text.strip() if subtitle_tag else \"Subtítulo não encontrado\"\n",
    "                except:\n",
    "                    subtitle = \"Subtítulo não encontrado\"\n",
    "                print(f\"[INFO] Subtítulo extraído: {subtitle}\")\n",
    "\n",
    "                # Extrai o texto da redação dentro da tag 'text-composition'\n",
    "                try:\n",
    "                    paragraphs = driver.find_elements(By.CSS_SELECTOR, \"div.text-composition p\")\n",
    "                    essay_text = \" \".join([p.text.strip() for p in paragraphs])\n",
    "                except:\n",
    "                    essay_text = \"Redação não encontrada\"\n",
    "                print(f\"[INFO] Texto da redação extraído.\")\n",
    "\n",
    "                # Extrai as competências e notas\n",
    "                try:\n",
    "                    competence_scores_section = driver.find_element(By.CSS_SELECTOR, \"section.results-table\")\n",
    "                    competence_scores_list = competence_scores_section.find_elements(By.CSS_SELECTOR, \"div.rt-line-option\")\n",
    "                    \n",
    "                    competences = []\n",
    "                    competence_scores = []\n",
    "                    final_score = \"Nota final não encontrada\"\n",
    "\n",
    "                    for score in competence_scores_list:\n",
    "                        topic = score.find_element(By.CSS_SELECTOR, \"span.topic\").text.strip()\n",
    "                        points = score.find_element(By.CSS_SELECTOR, \"span.points\").text.strip()\n",
    "                        \n",
    "                        competences.append(topic)\n",
    "                        competence_scores.append(points)\n",
    "\n",
    "                    # Verifica e extrai a última nota como \"Nota Final\" se houver mais de 5 notas\n",
    "                    if len(competence_scores) > 5:\n",
    "                        final_score = competence_scores.pop()  # Última nota removida das competências e usada como \"Nota Final\"\n",
    "                        competences.pop()  # Remove a última competência correspondente\n",
    "                except:\n",
    "                    competences, competence_scores, final_score = [], [], \"Erro ao extrair notas\"\n",
    "                print(f\"[INFO] Competências e notas extraídas.\")\n",
    "\n",
    "                # Extrai os comentários das competências\n",
    "                try:\n",
    "                    competence_comments_section = driver.find_element(By.XPATH, \"//h3[text()='Competências']/following-sibling::ul\")\n",
    "                    competence_comments_list = competence_comments_section.find_elements(By.TAG_NAME, \"li\")\n",
    "                    competence_comments = [comment.text.strip() for comment in competence_comments_list]\n",
    "                    concatenated_comments = \"; \".join(competence_comments)\n",
    "                except:\n",
    "                    concatenated_comments = \"Comentários não encontrados\"\n",
    "                \n",
    "                # Concatena as competências e as notas usando \";\" como separador\n",
    "                concatenated_competences = \"; \".join(competences)\n",
    "                concatenated_scores = \"; \".join(competence_scores)\n",
    "\n",
    "                # Escreve uma linha no CSV principal para cada URL processada\n",
    "                writer_main.writerow([record_id, title_id, title, subtitle, essay_text, concatenated_competences, concatenated_scores, concatenated_comments, final_score])\n",
    "\n",
    "                # Marca a URL como processada e salva no arquivo de links processados\n",
    "                with open(processed_links_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(url + \"\\n\")\n",
    "                \n",
    "                print(f\"[SUCCESS] Processado com sucesso: {url}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Erro ao acessar a página {url}: {e}\")\n",
    "\n",
    "# Salva o último ID usado\n",
    "with open(id_file, \"w\") as f:\n",
    "    f.write(str(last_id))\n",
    "\n",
    "# Salva o último ID de título usado\n",
    "with open(title_id_file, \"w\") as f:\n",
    "    f.write(str(last_title_id))\n",
    "\n",
    "# Fecha o navegador\n",
    "driver.quit()\n",
    "\n",
    "print(f\"[INFO] Arquivos CSV salvos em: {output_file} e {title_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com propostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/qualificacao-e-o-futuro-do-emprego.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/carnaval-e-apropriacao-cultural.html\",\n",
    "    \"https://educacao.uol.com.br/bancoderedacoes/propostas/supremo-tribunal-federal-e-opiniao-publica.html\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório e nome do arquivo CSV\n",
    "output_dir = \"textos_uol\"\n",
    "title_file = os.path.join(output_dir, \"titulos.csv\")\n",
    "\n",
    "# Lista para armazenar os textos das propostas extraídos\n",
    "textos_propostas = []\n",
    "\n",
    "print(\"Iniciando extração de textos das propostas...\")\n",
    "\n",
    "# Loop para processar cada URL e extrair o texto da proposta\n",
    "for index, url in enumerate(urls):\n",
    "    print(f\"\\nProcessando URL {index + 1}/{len(urls)}: {url}\")\n",
    "    try:\n",
    "        # Faz a requisição para obter o conteúdo da página\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Cria o objeto BeautifulSoup para analisar o HTML da página\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Localiza a cadeia de divs: article-wording -> calc-height -> image-content-pad -> text\n",
    "        article_wording = soup.find('div', class_='article-wording')\n",
    "        if article_wording:\n",
    "            calc_height = article_wording.find('div', class_='calc-height')\n",
    "            if calc_height:\n",
    "                image_content_pad = calc_height.find('div', class_='image-content-pad')\n",
    "                if image_content_pad:\n",
    "                    text_div = image_content_pad.find('div', class_='text')\n",
    "                    \n",
    "                    # Extrai o conteúdo das tags <p> dentro de \"text\"\n",
    "                    if text_div:\n",
    "                        paragraphs = text_div.find_all('p', recursive=False)\n",
    "                        text_proposal = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "                        print(f\"Texto extraído com sucesso da URL {index + 1}\")\n",
    "                    else:\n",
    "                        text_proposal = \"Seção de texto não encontrada na div 'text'.\"\n",
    "                        print(f\"Alerta: {text_proposal}\")\n",
    "                else:\n",
    "                    text_proposal = \"Div 'image-content-pad' não encontrada.\"\n",
    "                    print(f\"Alerta: {text_proposal}\")\n",
    "            else:\n",
    "                text_proposal = \"Div 'calc-height' não encontrada.\"\n",
    "                print(f\"Alerta: {text_proposal}\")\n",
    "        else:\n",
    "            text_proposal = \"Div 'article-wording' não encontrada.\"\n",
    "            print(f\"Alerta: {text_proposal}\")\n",
    "\n",
    "        # Adiciona o texto extraído à lista de resultados\n",
    "        textos_propostas.append(text_proposal)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_message = f\"Erro ao acessar a URL {url}: {e}\"\n",
    "        print(error_message)\n",
    "        textos_propostas.append(\"Erro ao acessar a página\")\n",
    "\n",
    "print(\"\\nExtração de propostas concluída.\")\n",
    "\n",
    "# Verifica se o arquivo CSV existe e lê os dados\n",
    "if os.path.exists(title_file):\n",
    "    print(f\"Lendo arquivo CSV existente: {title_file}\")\n",
    "    with open(title_file, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        fieldnames = reader.fieldnames\n",
    "        rows = list(reader)\n",
    "    print(\"Leitura concluída.\")\n",
    "\n",
    "    # Adiciona a coluna \"Textos Base\" se não estiver presente\n",
    "    if \"Textos Base\" not in fieldnames:\n",
    "        print(\"Adicionando coluna 'Textos Base' ao CSV.\")\n",
    "        fieldnames.append(\"Textos Base\")\n",
    "        for row in rows:\n",
    "            row[\"Textos Base\"] = \"\"  # Inicializa a coluna para cada linha existente\n",
    "else:\n",
    "    print(f\"Erro: O arquivo {title_file} não existe.\")\n",
    "    exit()\n",
    "\n",
    "# Adiciona os textos extraídos na coluna \"Textos Base\" na ordem dos URLs\n",
    "print(\"Atualizando o CSV com os textos extraídos...\")\n",
    "for i, row in enumerate(rows):\n",
    "    if i < len(textos_propostas):\n",
    "        row[\"Textos Base\"] = textos_propostas[i]\n",
    "\n",
    "# Escreve as mudanças de volta no arquivo CSV\n",
    "with open(title_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\nArquivo '{title_file}' atualizado com os textos das propostas na coluna 'Textos Base'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
